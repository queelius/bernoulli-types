\section{The Regular Types Philosophical Tension}
\label{sec:regular-types-tension}

\subsection{When Equality Isn't Equal}

Alexander Stepanov's concept of regular types forms the foundation of generic programming. A regular type must support equality comparison that is reflexive, symmetric, and transitive. But what happens when equality itself becomes probabilistic?

\begin{definition}[Regular Type Requirements]
A type $T$ is regular if it supports:
\begin{itemize}
\item \textbf{Copy construction}: \texttt{T a(b);} creates \texttt{a} as a copy of \texttt{b}
\item \textbf{Assignment}: \texttt{a = b;} makes \texttt{a} equal to \texttt{b}
\item \textbf{Equality}: \texttt{a == b} returns \texttt{true} iff \texttt{a} and \texttt{b} are equal
\item \textbf{Destruction}: Objects can be destroyed
\end{itemize}
With the semantic requirements:
\begin{itemize}
\item \textbf{Reflexive}: \texttt{a == a} is always \texttt{true}
\item \textbf{Symmetric}: \texttt{a == b} implies \texttt{b == a}
\item \textbf{Transitive}: \texttt{a == b} and \texttt{b == c} implies \texttt{a == c}
\end{itemize}
\end{definition}

But in our oblivious computing framework, equality comparison returns a Bernoulli Boolean:

\begin{lstlisting}[language=Python, caption={Bernoulli equality breaks regular type assumptions}]
class BernoulliInt:
    """Integer that can only be observed probabilistically"""
    
    def __init__(self, value: int, error_rate: float = 0.01):
        self.latent_value = value
        self.error_rate = error_rate
    
    def __eq__(self, other) -> BernoulliBool:
        """
        Equality returns a Bernoulli Boolean!
        We observe the latent equality through a noisy channel
        """
        latent_equal = (self.latent_value == other.latent_value)
        return BernoulliBool(latent_equal, self.error_rate)

# The philosophical crisis:
a = BernoulliInt(42)
b = BernoulliInt(42)
c = BernoulliInt(42)

# Reflexivity can fail!
assert a == a  # Might be false with probability ε!

# Symmetry can be violated in observation!
if observe(a == b):  # Observes true
    # But b == a might observe false!
    pass

# Transitivity fails!
if observe(a == b) and observe(b == c):
    # a == c is NOT guaranteed to observe true!
    pass
\end{lstlisting}

\subsection{The Deeper Truth: Equality as Observation}

The tension reveals a profound insight: equality comparison is itself a \textit{computation} that \textit{observes} the latent mathematical fact of equality.

\begin{theorem}[Equality as Channel]
When \texttt{operator==} returns $\mathcal{B}\langle\text{bool}, k\rangle$, equality becomes a channel:
\begin{equation}
\mathbb{P}[\text{observe } \texttt{a == b} = \text{true} | \text{latent } a = b] = 1 - \beta
\end{equation}
\begin{equation}
\mathbb{P}[\text{observe } \texttt{a == b} = \text{true} | \text{latent } a \neq b] = \alpha
\end{equation}
\end{theorem}

This models real-world scenarios:

\begin{example}[Distributed System Equality]
In a distributed database with eventual consistency:
\begin{lstlisting}[language=Python]
class DistributedValue:
    def __eq__(self, other):
        """
        Equality depends on:
        - Network latency (observations might be stale)
        - Replication lag (different nodes see different values)
        - Conflict resolution (concurrent updates)
        """
        # Query multiple replicas
        observations = []
        for replica in self.replicas:
            obs = replica.compare(self.id, other.id)
            observations.append(obs)
        
        # Majority vote (still probabilistic!)
        return BernoulliBool(
            value=majority_vote(observations),
            confidence=agreement_level(observations)
        )
\end{lstlisting}
\end{example}

\begin{example}[Floating-Point Equality]
Floating-point comparison is already a Bernoulli observation:
\begin{lstlisting}[language=C++]
// Traditional approach acknowledges observation error
bool approx_equal(double a, double b, double epsilon = 1e-10) {
    return std::abs(a - b) < epsilon;
}

// Bernoulli approach makes it explicit
bernoulli<bool> float_equal(double a, double b) {
    // Observation error depends on magnitude and precision
    double relative_error = std::abs(a - b) / std::max(std::abs(a), std::abs(b));
    double error_rate = 1.0 - std::exp(-relative_error / DBL_EPSILON);
    
    return bernoulli<bool>(
        std::abs(a - b) < DBL_EPSILON,  // Latent equality
        error_rate                        // Observation error
    );
}
\end{lstlisting}
\end{example}

\subsection{Reconciling Regular Types with Bernoulli Types}

Rather than abandoning regular types, we can extend them:

\begin{definition}[Bernoulli-Regular Type]
A type $T$ is Bernoulli-regular if:
\begin{itemize}
\item Equality returns $\mathcal{B}\langle\text{bool}, k\rangle$ instead of \texttt{bool}
\item Reflexivity holds \textit{in expectation}: $\mathbb{E}[\texttt{a == a}] \geq 1 - \epsilon$
\item Symmetry holds \textit{in distribution}: $\texttt{a == b} \sim \texttt{b == a}$
\item Transitivity holds \textit{probabilistically}: 
\begin{equation}
\mathbb{P}[\texttt{a == c} | \texttt{a == b} \land \texttt{b == c}] \geq 1 - 2\epsilon
\end{equation}
\end{itemize}
\end{definition}

\subsection{Practical Implications}

\subsubsection{Algorithm Design}

Algorithms must account for probabilistic equality:

\begin{lstlisting}[language=Python, caption={Hash table with Bernoulli equality}]
class BernoulliHashMap:
    """Hash map where equality comparisons might fail"""
    
    def get(self, key):
        bucket = self.hash(key) % self.size
        
        # Can't rely on single equality test!
        candidates = []
        for stored_key, value in self.buckets[bucket]:
            # Multiple observations for confidence
            observations = [key == stored_key for _ in range(3)]
            if majority_vote(observations):
                candidates.append((value, confidence(observations)))
        
        # Return most confident match
        if candidates:
            return max(candidates, key=lambda x: x[1])[0]
        return None
\end{lstlisting}

\subsubsection{Type System Design}

Languages could make observation explicit:

\begin{lstlisting}[language=C++, caption={Hypothetical type system with observation}]
template<typename T>
concept BernoulliRegular = requires(T a, T b) {
    { a == b } -> ObservableBool;  // Equality returns observable
    { a = b } -> T&;                // Assignment still deterministic
    { T(a) } -> T;                  // Copy still deterministic
};

// Compiler enforces observation
template<BernoulliRegular T>
void process(T a, T b) {
    if (observe(a == b)) {  // Must explicitly observe
        // Compiler knows this might be wrong
        // Can generate retry logic or confidence tracking
    }
}
\end{lstlisting}

\subsection{The Philosophical Shift}

This tension forces us to reconsider fundamental assumptions:

\begin{enumerate}
\item \textbf{Determinism is an illusion}: Even basic operations like equality involve observation through potentially faulty channels (hardware errors, cosmic rays, timing attacks)

\item \textbf{Algorithms are inherently probabilistic}: Every comparison, every memory access, every computation is an observation that might be wrong

\item \textbf{Correctness becomes statistical}: Instead of "this algorithm is correct," we have "this algorithm is correct with probability $1 - \epsilon$"

\item \textbf{Composition requires error tracking}: When equality isn't transitive, we must track error propagation through our programs
\end{enumerate}

\subsection{Benefits of Embracing Bernoulli-Regular Types}

Despite the complexity, accepting probabilistic equality enables:

\begin{itemize}
\item \textbf{Honest modeling of distributed systems}: Eventual consistency naturally fits
\item \textbf{Privacy by design}: Deliberately noisy equality provides differential privacy
\item \textbf{Fault tolerance}: Hardware errors become part of the model, not exceptions
\item \textbf{Approximate algorithms}: Trade perfect equality for massive performance gains
\end{itemize}

\begin{example}[Privacy-Preserving String Comparison]
\begin{lstlisting}[language=Python]
class PrivateString:
    """String with differentially private equality"""
    
    def __eq__(self, other):
        # Add noise for privacy
        if self.value == other.value:
            # True positive rate
            return BernoulliBool(True, error_rate=0.05)
        else:
            # Deliberate false positives for privacy
            distance = edit_distance(self.value, other.value)
            false_positive_rate = exp(-distance / self.privacy_parameter)
            return BernoulliBool(
                random.random() < false_positive_rate,
                error_rate=0.05
            )
\end{lstlisting}
\end{example}

\subsection{Conclusion: A New Foundation}

The tension between regular types and Bernoulli types isn't a bug—it's a feature. It reveals that:

\begin{quote}
\textit{Computation is observation. Every operation, including equality, observes latent mathematical truth through noisy channels. By acknowledging this in our type systems, we can build more honest, robust, and capable software.}
\end{quote}

Regular types assume we live in Plato's cave and can see the shadows perfectly. Bernoulli-regular types acknowledge that even the shadows are blurry—and show us how to work with that blur productively.