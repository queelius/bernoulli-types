\documentclass[11pt,final,hidelinks]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[margin=1in]{geometry}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,spacing=true,factor=1100,stretch=10,shrink=10]{microtype}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{algorithm2e}
\usepackage{hyperref}
\usepackage[square,numbers]{natbib}
\bibliographystyle{plainnat}
\usepackage{cleveref}

% Include unified notation for oblivious computing
\input{unified_notation_oblivious.tex}

% Additional notation
\newcommand{\Encode}[1]{\mathsf{encode}(#1)}
\newcommand{\ValidEnc}[1]{\mathsf{ValidEncodings}(#1)}
\newcommand{\Hash}[1]{h(#1)}
\newcommand{\Uniform}[1]{\mathcal{U}(#1)}
\newcommand{\Freq}[1]{\mathsf{freq}(#1)}

% Theorem environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{construction}[theorem]{Construction}
\newtheorem{principle}[theorem]{Principle}

\title{Addendum: Achieving Perfect Obliviousness through Uniform Encoding and Natural Noise}
\author{
    Alexander Towell\\
    \texttt{atowell@siue.edu}
}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
We present a fundamental principle for achieving perfect obliviousness in computing systems: maintaining uniform distribution at the observable layer through careful encoding design and natural noise injection. The key insight is that when we construct oblivious functions using hash-based encodings, we need not explicitly handle invalid inputs—they naturally map to random outputs, providing free noise that makes the system's observable behavior indistinguishable from random. By choosing encoding set sizes inversely proportional to value frequencies, we achieve uniform output distribution. Combined with deliberate noise queries using invalid inputs, this creates a system where real computations are perfectly hidden within random-looking behavior. This principle unifies and simplifies the construction of oblivious data structures, secure indexes, and private information retrieval systems.
\end{abstract}

\section{Introduction}

Traditional approaches to oblivious computing focus on:
\begin{itemize}
    \item Encrypting data and operations
    \item Adding explicit dummy operations
    \item Complex protocols to hide access patterns
\end{itemize}

We present a simpler, more fundamental approach:
\begin{itemize}
    \item Design encodings for uniform observable distribution
    \item Leverage natural randomness of hash functions
    \item Use invalid inputs as free noise source
\end{itemize}

\section{The Uniformity Principle}

\subsection{Core Principle}

\begin{principle}[Observable Uniformity]
Perfect obliviousness is achieved when the observable layer exhibits uniform distribution indistinguishable from random noise.
\end{principle}

For oblivious function $\hat{f}: \hat{X} \to \hat{Y}$:
\begin{itemize}
    \item Observable inputs: $P(\hat{x}) \approx 1/|\hat{X}|$ for all $\hat{x}$
    \item Observable outputs: $P(\hat{y}) \approx 1/|\hat{Y}|$ for all $\hat{y}$
    \item No patterns correlating inputs to outputs beyond random
\end{itemize}

\subsection{Achieving Uniformity through Encoding}

\begin{theorem}[Uniform Output Distribution]
For function $f: X \to Y$ with frequency distribution $\Freq{y} = |\{x : f(x) = y\}|$, uniform observable distribution is achieved by setting:
\begin{equation}
|\ValidEnc{y}| = \frac{C}{\Freq{y}}
\end{equation}
for some constant $C$.
\end{theorem}

\begin{proof}
The observable frequency of encoded value $e \in \ValidEnc{y}$ is:
\begin{equation}
P(\text{observe } e) = \frac{\Freq{y} \cdot 1/|\ValidEnc{y}|}{\sum_{y'} \Freq{y'}} = \frac{1}{C} = \text{constant}
\end{equation}
Thus all individual encodings appear with equal frequency.
\end{proof}

\section{Natural Noise from Invalid Inputs}

\subsection{The Free Lunch of Randomness}

\begin{theorem}[Invalid Input Distribution]
For hash-based oblivious function $\hat{f}$ with seed $s$:
\begin{itemize}
    \item Valid inputs $x \in X$: $\Hash{\Encode{x} \| s} \in \ValidEnc{f(x)}$ (by construction)
    \item Invalid inputs $u \notin \{\Encode{x} : x \in X\}$: $\Hash{u \| s} \sim \Uniform{\{0,1\}^m}$
\end{itemize}
Invalid inputs naturally map uniformly over the output space.
\end{theorem}

\begin{corollary}[No Special Handling Required]
Invalid inputs need no special handling—the hash function automatically provides uniform noise.
\end{corollary}

\subsection{Noise Injection Strategy}

\begin{construction}[Active Noise Injection]
To hide real query patterns:
\begin{algorithm}[H]
\caption{Query with Noise Injection}
\KwIn{Real queries $Q_{\text{real}}$, noise rate $\rho$}
\For{$q \in Q_{\text{real}}$}{
    Submit $\hat{f}(\Encode{q})$\;
    \uIf{$\text{random}() < \rho$}{
        $u \leftarrow \text{random bits}$\;
        Submit $\hat{f}(u)$ \tcp{Invalid input, maps randomly}
    }
}
\end{algorithm}
Observer sees uniform mixture of real and noise queries.
\end{construction}

\section{Composition while Maintaining Uniformity}

\subsection{The Challenge}

When composing oblivious functions $\hat{g} \circ \hat{f}$:
\begin{itemize}
    \item Each function maintains uniformity individually
    \item Composition must preserve uniformity
    \item Invalid inputs must flow through naturally
\end{itemize}

\subsection{The Solution}

\begin{theorem}[Uniform Composition]
If $\hat{f}: \hat{X} \to \hat{Y}$ and $\hat{g}: \hat{Y} \to \hat{Z}$ both maintain uniformity, then $\hat{g} \circ \hat{f}$ maintains uniformity when:
\begin{enumerate}
    \item Valid path: $x \to \hat{f}(x) \to \hat{g}(\hat{f}(x))$ proceeds correctly
    \item Invalid path: $u \to \text{random} \to \text{random}$ propagates randomness
    \item All intermediate values in $\hat{Y}$ appear uniformly
\end{enumerate}
\end{theorem}

\begin{remark}[Noise Propagation]
Invalid inputs create a "river of noise" flowing through the computation:
\begin{itemize}
    \item Each stage preserves randomness
    \item Real computations hide within noise
    \item No correlation between stages for invalid inputs
\end{itemize}
\end{remark}

\section{Application to Oblivious Data Structures}

\subsection{Oblivious Maps}

For map $M: K \to V$:

\begin{construction}[Uniform Oblivious Map]
\begin{enumerate}
    \item Count frequency: $\Freq{v} = |\{k : M(k) = v\}|$
    \item Set encoding sizes: $|\ValidEnc{v}| \propto 1/\Freq{v}$
    \item Find seed where keys map correctly
    \item Invalid keys map uniformly to all possible encodings
\end{enumerate}
Result: Observable outputs uniformly distributed.
\end{construction}

\subsection{Oblivious Sets}

\begin{example}[Uniform Bloom Filter]
Traditional Bloom: Fixed false positive rate $\alpha$

Uniform Bloom:
\begin{itemize}
    \item If set has $n$ elements out of universe size $N$
    \item Set $|\ValidEnc{\text{True}}| = N/n \cdot |\ValidEnc{\text{False}}|$
    \item Result: "member" and "non-member" responses equally likely
    \item Perfect hiding of set density
\end{itemize}
\end{example}

\section{System-Level Design}

\subsection{End-to-End Obliviousness}

\begin{principle}[Holistic Design]
Design the entire system for uniformity, not individual components:
\begin{itemize}
    \item Input encoding: Pad/encode to uniform distribution
    \item Processing: Maintain uniformity through operations
    \item Output encoding: Ensure uniform final distribution
    \item Timing: Constant-time operations or random delays
\end{itemize}
\end{principle}

\subsection{Practical Implementation}

\begin{verbatim}
class ObliviousSystem:
    def __init__(self, function_f):
        self.f = function_f
        self.compute_frequencies()
        self.design_encodings()  # Inverse proportional to frequency
        self.seed = self.find_seed()
        
    def query(self, x, with_noise=True):
        # Real query
        result = self.hash_eval(encode(x))
        
        # Automatic noise
        if with_noise:
            for _ in range(random_poisson(lambda=1)):
                noise = random_bits()
                self.hash_eval(noise)  # Discarded but observable
                
        return decode(result)
        
    def hash_eval(self, encoded_input):
        return h(encoded_input || self.seed)
\end{verbatim}

\section{Privacy Analysis}

\subsection{Information-Theoretic Security}

\begin{theorem}[Perfect Hiding]
When observable distribution is uniform:
\begin{equation}
I(\text{Computation}; \text{Observation}) = 0
\end{equation}
The observation reveals zero information about the actual computation.
\end{theorem}

\subsection{Practical Security}

\begin{proposition}[Computational Indistinguishability]
Even with computational bounds, distinguishing real from random requires:
\begin{itemize}
    \item Breaking hash function randomness, or
    \item Observing enough queries to detect statistical bias
    \item Both require exponential resources for well-designed systems
\end{itemize}
\end{proposition}

\section{Comparison with Traditional Approaches}

\begin{center}
\begin{tabular}{lll}
\textbf{Aspect} & \textbf{Traditional} & \textbf{Uniform Encoding} \\
\hline
Noise & Explicit dummy ops & Natural from invalid inputs \\
Uniformity & Approximate & Exact by design \\
Complexity & Complex protocols & Simple hash evaluation \\
Composition & Difficult & Natural propagation \\
Performance & High overhead & Single hash per operation \\
\end{tabular}
\end{center}

\section{Design Guidelines}

\subsection{When to Use Uniform Encoding}

\begin{itemize}
    \item \textbf{Best for}: Systems where output distribution is known/controllable
    \item \textbf{Examples}: Databases, key-value stores, search indexes
    \item \textbf{Advantages}: Perfect hiding, simple implementation
\end{itemize}

\subsection{When Traditional Methods Are Better}

\begin{itemize}
    \item \textbf{Best for}: Arbitrary computations with complex patterns
    \item \textbf{Examples}: General program execution, complex queries
    \item \textbf{Advantages}: More flexible, handles any computation
\end{itemize}

\section{Advanced Techniques}

\subsection{Adaptive Encoding}

\begin{construction}[Dynamic Uniformity]
Adjust encoding sizes online:
\begin{enumerate}
    \item Monitor actual frequency distribution
    \item Periodically recompute encoding sizes
    \item Find new seed maintaining uniformity
    \item Seamlessly transition to new encoding
\end{enumerate}
\end{construction}

\subsection{Differential Privacy Integration}

\begin{remark}[Complementary Techniques]
Uniform encoding provides:
\begin{itemize}
    \item Perfect hiding of individual operations
    \item Natural noise injection
\end{itemize}
Add differential privacy for:
\begin{itemize}
    \item Protecting aggregate statistics
    \item Formal privacy guarantees
\end{itemize}
Combined: Best of both worlds.
\end{remark}

\section{Implications for Oblivious Computing}

\subsection{Simplified Mental Model}

Instead of thinking about:
\begin{itemize}
    \item Complex encryption schemes
    \item Dummy operation patterns
    \item Access pattern hiding protocols
\end{itemize}

Think about:
\begin{itemize}
    \item Making observables uniform
    \item Letting hash randomness work for you
    \item Invalid inputs as free noise
\end{itemize}

\subsection{New Design Space}

This opens new possibilities:
\begin{itemize}
    \item \textbf{Partially oblivious}: Make only sensitive operations uniform
    \item \textbf{Selective noise}: Inject noise only during sensitive periods
    \item \textbf{Graduated privacy}: Different uniformity levels for different users
\end{itemize}

\section{Conclusion}

The principle of achieving obliviousness through uniform encoding and natural noise dramatically simplifies the construction of privacy-preserving systems:

\textbf{Key Insights:}
\begin{itemize}
    \item \textbf{Uniformity is obliviousness}: Uniform distribution = perfect hiding
    \item \textbf{Encoding design is crucial}: Size encodings inversely to frequency
    \item \textbf{Noise is free}: Invalid inputs naturally provide cover
    \item \textbf{Composition is natural}: Randomness propagates automatically
\end{itemize}

\textbf{Practical Impact:}
\begin{itemize}
    \item Simpler implementations
    \item Better performance (single hash evaluation)
    \item Stronger privacy guarantees
    \item Natural composition of oblivious components
\end{itemize}

This principle should be the default approach for oblivious computing systems where the output distribution can be controlled through encoding design.

\bibliography{references}

\end{document}