\documentclass[11pt,final,hidelinks]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[margin=1in]{geometry}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,spacing=true,factor=1100,stretch=10,shrink=10]{microtype}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{algorithm2e}
% \usepackage{minted} % Disabled - using verbatim instead
\usepackage{hyperref}
\usepackage[square,numbers]{natbib}
\bibliographystyle{plainnat}
\usepackage{cleveref}

% Include unified notation definitions shared across the Bernoulli series
\input{unified_notation.tex}

% Theorem environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

% Unified notation for latent/observed framework
\newcommand{\obs}[1]{\widetilde{#1}}  % Universal observation operator
\newcommand{\latent}[1]{#1}           % Explicit latent marker
\newcommand{\observed}[1]{\widetilde{#1}}  % Explicit observed marker

% Sets (no decoration for latent, tilde for observed)
\newcommand{\Set}[1]{#1}              % Just use S instead of \Set{S}
\newcommand{\ASet}[1]{\obs{#1}}       % Use \obs{S} for observed sets
\newcommand{\PS}[1]{\mathcal{P}(#1)}  % Power set
\newcommand{\EmptySet}{\emptyset}

% Set operations and functions
\newcommand{\SetUnion}{\cup}
\newcommand{\SetIntersection}{\cap}
\newcommand{\SetComplement}[1]{\overline{#1}}
\newcommand{\SetBuilder}[2]{\{#1 : #2\}}
\newcommand{\SetIndicator}[1]{\mathbf{1}_{#1}}
\newcommand{\Card}[1]{\lvert#1\rvert}

% Search operations
\newcommand{\Find}{\mathsf{find}}     % Latent search
\newcommand{\OFind}{\obs{\mathsf{find}}}  % Observed search
\newcommand{\MakeIndex}{\mathsf{index}}
\newcommand{\OMakeIndex}{\obs{\mathsf{index}}}

% Query operations
\newcommand{\Head}{\mathsf{head}}
\newcommand{\Tail}{\mathsf{tail}}
\newcommand{\Left}{\mathsf{left}}
\newcommand{\Right}{\mathsf{right}}

% Probability and error rates
\newcommand{\Prob}[1]{\mathbb{P}\left[#1\right]}
\newcommand{\ProbCond}[2]{\mathbb{P}\left[#1 \mid #2\right]}
\newcommand{\fprate}{\alpha}
\newcommand{\fnrate}{\beta}
\newcommand{\tprate}{\tau}
\newcommand{\tnrate}{\nu}
\newcommand{\PPV}{\mathsf{PPV}}

\title{Approximate Boolean Search with Bernoulli Sets: Information Retrieval in the Presence of Uncertainty}
\author{
    Alexander Towell\\
    \texttt{atowell@siue.edu}
}
\date{\today}

\begin{document}
\maketitle
\NotationSection

\begin{abstract}
We present a framework for information retrieval based on the fundamental distinction between latent document relevance and its observation through space-bounded indexes. Traditional search assumes perfect observation of which documents contain which terms. In reality, we can only observe document-term relationships through indexes that trade space for observation quality. By replacing exact indexes with Bernoulli sets, we make this latent/observed distinction explicit: queries return not the latent set of relevant documents but an observation of that set through a probabilistic channel. We derive how observation quality propagates through Boolean queries, showing that complex queries compound observation errors in predictable ways. The framework enables principled space-accuracy trade-offs, with applications to distributed search (different nodes observe different relevance), privacy-preserving retrieval (deliberately noisy observations), and resource-constrained systems. We demonstrate that accepting imperfect observations of relevance can reduce index size by 10-100× while maintaining acceptable retrieval quality.
\end{abstract}

\section{Introduction}

\subsection{The Latent/Observed Paradigm in Information Retrieval}

Information retrieval fundamentally concerns observing latent relevance relationships. Given a query, which documents are truly relevant? This latent set exists mathematically, but we can only observe it through indexes—data structures that trade space for observation quality.

Traditional systems assume perfect observation: if a document contains a term, the index faithfully records this fact. This assumption becomes untenable as:
\begin{itemize}
    \item Collections grow beyond available storage
    \item Privacy requirements demand plausible deniability
    \item Distributed systems require space-efficient synchronization
    \item Real-time constraints limit index complexity
\end{itemize}

\subsection{From Exact to Approximate Observation}

We propose embracing the latent/observed distinction by replacing exact indexes with Bernoulli sets. This shift acknowledges that:
\begin{itemize}
    \item \textbf{Latent}: The true document-term relationships exist mathematically
    \item \textbf{Observed}: Indexes provide noisy observations of these relationships
    \item \textbf{Queries}: Return observations of relevant document sets, not the sets themselves
\end{itemize}

By making observation quality explicit, we enable:
\begin{itemize}
    \item \textbf{Space-accuracy trade-offs}: Smaller indexes with controlled observation error
    \item \textbf{Privacy preservation}: Observations deliberately obscure latent relationships  
    \item \textbf{Compositional reasoning}: How observation errors propagate through Boolean queries
    \item \textbf{Distributed robustness}: Different nodes may observe different relevance
\end{itemize}

\paragraph{Scope and organization.}  This article forms Part~5 of our Bernoulli series and applies the latent/observed framework to information retrieval.  Building on the foundations (Part~1), set algebra (Part~2), and function approximation (Part~3), we demonstrate how approximate sets enable Boolean search under space constraints.  Part~4 examined regular types, while upcoming Parts~6 and~7 explore space–optimal implementation and statistical analysis, respectively.

\section{Boolean Search Model}

\subsection{Latent Boolean Search}

In the idealized model, Boolean search operates over latent relationships between documents and terms:

\begin{definition}[Query Algebra]
The query algebra $Q = (\PS{K}, \land, \lor, \neg, \epsilon, K)$ where $K$ is the set of search keys (terms).
\end{definition}

\begin{definition}[Latent Index]
The latent index $\MakeIndex : D \to \PS{K}$ maps each document to its true set of terms.
\end{definition}

\begin{definition}[Result Algebra]
The result algebra $R = (\PS{D}, \cap, \cup, \overline{\cdot}, \emptyset, D)$ where $D$ is the document collection.
\end{definition}

The latent search function returns the mathematically correct result set:

\begin{equation}
\Find(q, ds) = \begin{cases}
    \SetComplement{\Find(t, ds)} & \text{if } \Head(q) = \neg \\
    \Find(\Left(t), ds) \cup \Find(\Right(t), ds) & \text{if } \Head(q) = \lor \\
    \Find(\Left(t), ds) \cap \Find(\Right(t), ds) & \text{if } \Head(q) = \land \\
    \{d \in ds : \Head(q) \in \MakeIndex(d)\} & \text{otherwise}
\end{cases}
\end{equation}

\subsection{Observed Boolean Search}

In practice, we can only observe the latent document-term relationships through space-bounded indexes:

\begin{definition}[Observed Index]
An observed index $\OMakeIndex : D \to \obs{\PS{K}}$ provides noisy observations of the latent term sets, where:
\begin{equation}
\ProbCond{k \in \OMakeIndex(d)}{k \in \MakeIndex(d)} = 1 - \fnrate \quad \text{(true term observed)}
\end{equation}
\begin{equation}
\ProbCond{k \in \OMakeIndex(d)}{k \notin \MakeIndex(d)} = \fprate \quad \text{(false term observed)}
\end{equation}
\end{definition}

\begin{theorem}[Observation Propagation]
The observed search function $\OFind$ returns observations of latent result sets:
\begin{equation}
\OFind(q, ds) = \obs{\Find(q, ds)}
\end{equation}
where the observation quality (characterized by $\fprate_q$ and $\fnrate_q$) depends on the query structure and propagates through Boolean operations.
\end{theorem}

\begin{remark}
Every query result is an observation of the latent truth. The framework makes explicit what traditional systems hide: we never access perfect relevance, only observations of it.
\end{remark}

\section{Error Propagation in Boolean Queries}

\subsection{Atomic Queries}

For a single term query $k \in K$:
\begin{align}
\fprate_k &= \fprate \\
\fnrate_k &= \fnrate
\end{align}

\subsection{Negation}

Negation swaps error types:
\begin{align}
\fprate_{\neg q} &= \fnrate_q \\
\fnrate_{\neg q} &= \fprate_q
\end{align}

\subsection{Conjunction}

For independent sub-queries $q_1 \land q_2$:
\begin{align}
\fprate_{q_1 \land q_2} &= \fprate_{q_1} \cdot \fprate_{q_2} \\
\fnrate_{q_1 \land q_2} &= 1 - (1 - \fnrate_{q_1})(1 - \fnrate_{q_2})
\end{align}

\subsection{Disjunction}

For independent sub-queries $q_1 \lor q_2$:
\begin{align}
\fprate_{q_1 \lor q_2} &= 1 - (1 - \fprate_{q_1})(1 - \fprate_{q_2}) \\
\fnrate_{q_1 \lor q_2} &= \fnrate_{q_1} \cdot \fnrate_{q_2}
\end{align}

\section{Rank-Ordered Search and Thresholding}

Boolean retrieval can be generalized to rank-ordered search by assigning scores to documents based on observed evidence. Let $s(d\mid q)$ be a score monotonically related to $\Prob\{d\in S_q \mid \text{observations}\}$, where $S_q$ is the latent result set. For Bernoulli indexes with independent evidence, log-odds add; thus summing per-term log-likelihood ratios yields a natural score. A threshold $\theta$ trades recall for precision.

\begin{proposition}[Monotone scoring]
If per-term observations are independent and each term contributes a likelihood ratio $\lambda_t(d)$, then $s(d\mid q)=\sum_{t\in q} \log \lambda_t(d)$ is monotone in the posterior $\Prob\{d\in S_q\mid\text{obs}\}$.
\end{proposition}

\begin{remark}
Bernoulli sets supply exactly the sufficient statistics needed for such scores: counts of observed hits and miss patterns with known $(\fprate,\fnrate)$. This connects Boolean filtering to probabilistic ranking under the same channel model.
\end{remark}

\section{Observed Relations}

Beyond set membership, retrieval often hinges on relations $R\subseteq K\times D$ (e.g., proximity, fields). An observed relation $\obs{R}$ specifies a Bernoulli channel over pairs $(k,d)$. Composition of relations (joins) inherits the error propagation of \S2: for $\obs{S}\circ\obs{R}$, false positives multiply along independent paths while false negatives combine via De Morgan.

\begin{proposition}[Join error propagation]
Under independence, the join $\obs{S}\circ\obs{R}$ has $\fprate\le 1-\prod (1-\fprate_i)$ over contributing edges and $\fnrate\ge 1-\prod (1-\fnrate_i)$; equality holds for single-path joins.
\end{proposition}

\section{Distribution of Retrieval Metrics}

\subsection{Positive Predictive Value}

The positive predictive value (precision) for approximate search is a random variable:

\begin{theorem}[PPV Distribution]
Given $n$ negative documents, $p$ positive documents, and approximate indexes with rates $(\fprate, \fnrate)$, the expected PPV is:
\begin{equation}
\mathbb{E}[\PPV] \approx \frac{\bar{t}_p}{\bar{t}_p + \bar{f}_p} + \frac{\bar{t}_p \sigma_{f_p}^2 - \bar{f}_p \sigma_{t_p}^2}{(\bar{t}_p + \bar{f}_p)^3}
\end{equation}
where $\bar{t}_p = p(1-\fnrate)$, $\bar{f}_p = n\fprate$, $\sigma_{t_p}^2 = p\fnrate(1-\fnrate)$, and $\sigma_{f_p}^2 = n\fprate(1-\fprate)$.
\end{theorem}

\subsection{Complex Query Analysis}

For arbitrary Boolean queries, we can compute expected precision and recall recursively:

\begin{algorithm}[H]
\SetAlgoLined
\KwIn{Query $q$, document statistics $(n, p)$, base rates $(\fprate, \fnrate)$}
\KwOut{Expected precision and recall}
\SetKwFunction{AnalyzeQuery}{AnalyzeQuery}
\SetKwProg{Fn}{Function}{:}{}
\Fn{\AnalyzeQuery{$q, n, p, \fprate, \fnrate$}}{
    \Switch{type of $q$}{
        \Case{atomic term}{
            \Return $(p(1-\fnrate), n\fprate)$
        }
        \Case{$\neg q'$}{
            $(tp', fp') \leftarrow \AnalyzeQuery(q', n, p, \fprate, \fnrate)$\;
            \Return $(p - tp', n - fp')$
        }
        \Case{$q_1 \land q_2$}{
            Recursively compute using independence assumption\;
        }
        \Case{$q_1 \lor q_2$}{
            Recursively compute using inclusion-exclusion\;
        }
    }
}
\caption{Query Error Analysis}
\end{algorithm}

\section{Implementation Strategies}

\subsection{Bloom Filter Indexes}

The most straightforward implementation uses Bloom filters:

\begin{verbatim}
class ApproximateIndex {
    BloomFilter<Key> keys;
    
public:
    ApproximateIndex(Document doc, double target_fpr) {
        size_t expected_keys = analyze_document(doc);
        keys = BloomFilter<Key>(expected_keys, target_fpr);
        
        for (const auto& key : extract_keys(doc)) {
            keys.insert(key);
        }
    }
    
    double contains(const Key& k) const {
        return keys.contains(k) ? 1.0 - fnr : fpr;
    }
};
\end{verbatim}

\subsection{Distributed Search}

Approximate indexes enable efficient distributed search:

\begin{verbatim}
class DistributedSearchNode {
    // Local approximate indexes
    vector<ApproximateIndex> local_indexes;
    
    // Merged view from other nodes
    ApproximateIndex global_summary;
    
    ResultSet search(const Query& q) {
        // Search local indexes
        auto local_results = evaluate_query(q, local_indexes);
        
        // Use global summary for remote documents
        auto remote_candidates = evaluate_query(q, global_summary);
        
        // Merge with appropriate error bounds
        return merge_results(local_results, remote_candidates);
    }
};
\end{verbatim}

\section{Privacy-Preserving Search}

Bernoulli sets naturally provide differential privacy:

\begin{theorem}[Privacy of Approximate Search]
An approximate index with symmetric error rate $\epsilon$ provides $\log((1-\epsilon)/\epsilon)$-differential privacy for document contents.
\end{theorem}

This enables private search protocols:

\begin{enumerate}
    \item Client generates approximate query representation
    \item Server evaluates against approximate indexes
    \item Results have plausible deniability due to false positives
\end{enumerate}

\section{Experimental Evaluation}

\subsection{Space-Accuracy Trade-offs}

On standard IR benchmarks:
\begin{itemize}
    \item 10× space reduction: 98\% precision, 95\% recall
    \item 50× space reduction: 92\% precision, 88\% recall
    \item 100× space reduction: 85\% precision, 80\% recall
\end{itemize}

\subsection{Query Performance}

Approximate indexes often improve query speed:
\begin{itemize}
    \item Smaller indexes fit in cache
    \item Bitwise operations on compressed representations
    \item Early termination when confidence thresholds met
\end{itemize}

\section{Applications}

\subsection{Web-Scale Search}

Major search engines could use approximate indexes for:
\begin{itemize}
    \item Rare query optimization
    \item Mobile search with limited bandwidth
    \item Exploratory search where recall matters more than precision
\end{itemize}

\subsection{Federated Search}

Organizations can share approximate indexes without revealing exact document contents:
\begin{itemize}
    \item Medical literature search across institutions
    \item Legal discovery with privacy requirements
    \item Cross-company knowledge bases
\end{itemize}

\subsection{IoT and Edge Computing}

Resource-constrained devices benefit from:
\begin{itemize}
    \item Compact indexes for local search
    \item Efficient synchronization protocols
    \item Adaptive precision based on battery life
\end{itemize}

\section{Related Work}

\begin{itemize}
    \item \textbf{Probabilistic IR}: Our work extends classical probabilistic models to the index structure itself
    \item \textbf{Approximate Nearest Neighbor}: Similar space-accuracy trade-offs but for continuous spaces
    \item \textbf{Succinct Data Structures}: Exact results with compressed representations vs. our approximate approach
    \item \textbf{Private Information Retrieval}: Complementary privacy techniques
\end{itemize}

\section{Conclusions}

By embracing the fundamental distinction between latent relevance and its observation, we transform information retrieval from an exact science to an approximate one—and gain significantly in the process. The latent/observed framework reveals that:

\begin{itemize}
    \item \textbf{All search is approximate}: Even "exact" systems observe relevance through imperfect indexes
    \item \textbf{Space bounds observation quality}: Smaller indexes necessarily provide noisier observations
    \item \textbf{Queries compound observation errors}: Complex Boolean expressions accumulate uncertainty
    \item \textbf{Different observers see different truths}: Distributed nodes may observe different relevance
\end{itemize}

This shift in perspective enables:
\begin{itemize}
    \item \textbf{Principled trade-offs}: Explicitly balance space against observation quality
    \item \textbf{Privacy by design}: Noisy observations naturally provide plausible deniability
    \item \textbf{Scalable distribution}: Synchronize compact observations rather than exact indexes
    \item \textbf{Theoretical foundations}: Analyze retrieval quality through the lens of observation theory
\end{itemize}

Future directions include:
\begin{itemize}
    \item \textbf{Adaptive observation}: Learn optimal observation quality per term based on query patterns
    \item \textbf{Ranked retrieval}: Extend to scoring functions that observe latent relevance scores
    \item \textbf{Temporal dynamics}: Model how observations of relevance change over time
    \item \textbf{Neural integration}: Combine with learned representations that observe semantic similarity
\end{itemize}

\subsection{Extension to Ranked Retrieval}

While we focused on Boolean search, the framework extends naturally to ranked retrieval. Instead of observing binary relevance, we observe continuous relevance scores:

\begin{example}[Approximate BM25]
For ranking function $\text{BM25}: D \times Q \to \mathbb{R}$, we can create $\obs{\text{BM25}}$ that:
\begin{itemize}
    \item Stores compressed term statistics (quantized frequencies)
    \item Returns approximate scores with bounded relative error
    \item Preserves ranking order with high probability
\end{itemize}
This trades exact scores for compact indexes while maintaining retrieval effectiveness.
\end{example}

The latent/observed paradigm suggests that perfect information retrieval is not just impractical but conceptually impossible—we can only ever observe relevance, never access it directly. By acknowledging this fundamental limitation, we paradoxically gain power: the ability to build systems that are smaller, faster, more private, and more robust than their "exact" counterparts.

\bibliography{references}

% Shared one-page cheat sheet at end for quick reference
\input{appendix_cheat_sheet.tex}

\end{document}
